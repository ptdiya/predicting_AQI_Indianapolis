{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b74f8f5e-6354-4933-8b54-93b76f64b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GatedLinearUnit(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(GatedLinearUnit, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        self.gate = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x) * torch.sigmoid(self.gate(x))\n",
    "\n",
    "class LayerNormLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, bidirectional):\n",
    "        super(LayerNormLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, hidden_size, num_layers=num_layers,\n",
    "            batch_first=True, dropout=dropout, bidirectional=bidirectional\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size * (2 if bidirectional else 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        lstm_out = self.layer_norm(lstm_out)\n",
    "        return lstm_out\n",
    "\n",
    "class LayerDropLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, bidirectional, layer_drop_prob=0.2):\n",
    "        super(LayerDropLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout, bidirectional=bidirectional)\n",
    "        self.layer_drop_prob = layer_drop_prob\n",
    "        self.projection = nn.Linear(input_size, hidden_size * (2 if bidirectional else 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and torch.rand(1).item() < self.layer_drop_prob:\n",
    "            return self.projection(x)  # Project input to match LSTM output size\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        return lstm_out\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=hidden_size, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "        return attn_output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_embedding = nn.Embedding(max_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        positions = torch.arange(0, seq_len, dtype=torch.long, device=x.device).unsqueeze(0)\n",
    "        pos_enc = self.pos_embedding(positions)\n",
    "        return x + pos_enc\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.tanh(F.softplus(x))\n",
    "\n",
    "\n",
    "class ResidualLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, bidirectional):\n",
    "        super(ResidualLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout, bidirectional=bidirectional)\n",
    "        self.projection = nn.Linear(hidden_size * (2 if bidirectional else 1), hidden_size * (2 if bidirectional else 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        projected_out = self.projection(lstm_out)\n",
    "        return projected_out\n",
    "\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, lstm_dropout=0.3, fcn_dropout=0.5, debug=False):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.bidirectional = True\n",
    "        self.num_directions = 2 if self.bidirectional else 1\n",
    "        self.debug = debug\n",
    "        \n",
    "        self.num_heads = 8\n",
    "        self.hidden_size = hidden_size // (self.num_directions * 3)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"Adjusted hidden_size: {self.hidden_size}\")\n",
    "        \n",
    "        self.embedding_size = input_size\n",
    "\n",
    "        self.positional_encoding = PositionalEncoding(self.embedding_size)\n",
    "\n",
    "        self.lstm1 = LayerNormLSTM(\n",
    "            self.embedding_size, self.hidden_size, num_layers=num_layers,\n",
    "            dropout=lstm_dropout, bidirectional=self.bidirectional\n",
    "        )\n",
    "        self.lstm2 = ResidualLSTM(\n",
    "            self.embedding_size, self.hidden_size, num_layers=num_layers,\n",
    "            dropout=lstm_dropout, bidirectional=self.bidirectional\n",
    "        )\n",
    "        self.lstm3 = LayerDropLSTM(\n",
    "            self.embedding_size, self.hidden_size, num_layers=num_layers,\n",
    "            dropout=lstm_dropout, bidirectional=self.bidirectional\n",
    "        )\n",
    "\n",
    "        self.combined_lstm_size = self.hidden_size * self.num_directions * 3\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"Combined LSTM size: {self.combined_lstm_size}\")\n",
    "            print(f\"Number of heads: {self.num_heads}\")\n",
    "            print(f\"Is combined_lstm_size divisible by num_heads? {self.combined_lstm_size % self.num_heads == 0}\")\n",
    "\n",
    "        self.transformer_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.combined_lstm_size,\n",
    "            nhead=self.num_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            self.transformer_layer, num_layers=3\n",
    "        )\n",
    "\n",
    "        self.attention = MultiHeadSelfAttention(self.combined_lstm_size, self.num_heads)\n",
    "\n",
    "        self.glu1 = GatedLinearUnit(self.combined_lstm_size, self.combined_lstm_size // 2)\n",
    "        self.glu2 = GatedLinearUnit(self.combined_lstm_size // 2, self.combined_lstm_size // 4)\n",
    "\n",
    "        self.fc = nn.Linear(self.combined_lstm_size // 4, num_classes)\n",
    "\n",
    "        self.layer_norm2 = nn.LayerNorm(self.combined_lstm_size // 2)\n",
    "        self.layer_norm3 = nn.LayerNorm(self.combined_lstm_size // 4)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=fcn_dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.positional_encoding(x)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"Shape after positional encoding: {x.shape}\")\n",
    "\n",
    "        lstm_out1 = self.lstm1(x)\n",
    "        lstm_out2 = self.lstm2(x)\n",
    "        lstm_out3 = self.lstm3(x)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"Shape of lstm_out1: {lstm_out1.shape}\")\n",
    "            print(f\"Shape of lstm_out2: {lstm_out2.shape}\")\n",
    "            print(f\"Shape of lstm_out3: {lstm_out3.shape}\")\n",
    "\n",
    "        lstm_out_concat = torch.cat((lstm_out1, lstm_out2, lstm_out3), dim=-1)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"Shape after concatenation: {lstm_out_concat.shape}\")\n",
    "\n",
    "        transformer_out = self.transformer_encoder(lstm_out_concat)\n",
    "        transformer_out = lstm_out_concat + transformer_out  \n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"Shape after transformer: {transformer_out.shape}\")\n",
    "\n",
    "        attn_out = self.attention(transformer_out)\n",
    "        attn_out = transformer_out + attn_out \n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"Shape after attention: {attn_out.shape}\")\n",
    "\n",
    "        global_avg_pool = torch.mean(attn_out, dim=1)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"Shape after global average pooling: {global_avg_pool.shape}\")\n",
    "            \n",
    "        out = self.glu1(global_avg_pool)\n",
    "        out = self.layer_norm2(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"Shape after first GLU: {out.shape}\")\n",
    "\n",
    "        out = self.glu2(out)\n",
    "        out = self.layer_norm3(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"Shape after second GLU: {out.shape}\")\n",
    "\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"Final output shape: {out.shape}\")\n",
    "\n",
    "        return out\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha, gamma=2.5, reduction='mean', label_smoothing=0.1):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = torch.tensor(alpha) \n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.label_smoothing = label_smoothing\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        num_classes = inputs.size(1)\n",
    "        smoothed_labels = F.one_hot(targets, num_classes=num_classes)\n",
    "        smoothed_labels = smoothed_labels * (1 - self.label_smoothing) + self.label_smoothing / num_classes\n",
    "\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha[targets] * (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc3d2a2b-df9e-4422-b17a-e5dfc80e2bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 35\n",
    "hidden_size = 384 #should be divisible by (num_directions * 3 * num_heads) # multiple of 86\n",
    "num_layers = 2\n",
    "num_epochs = 55\n",
    "num_classes = 5\n",
    "bagging = 5\n",
    "batch_size = 16\n",
    "early_stop_patience = 10\n",
    "subset_size = 555\n",
    "alpha_np = [0.70, 0.27, 0.01, 0.01, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "915e24b5-2209-437d-be58-fdc2d0465558",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(input_size, hidden_size, num_layers, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6281e60a-c94c-4713-8620-9d7d4c65df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "merged_data_2024_test_cleaned = pd.read_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fe83476-03e6-4328-89a6-559c074167ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_numeric = merged_data_2024_test_cleaned.select_dtypes(include=[float, int])\n",
    "\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_numeric.values, dtype=torch.float32)\n",
    "\n",
    "def create_sequences_test(X, seq_length):\n",
    "    sequences = []\n",
    "    for i in range(seq_length, len(X)):\n",
    "        X_seq = X[i-seq_length:i]\n",
    "        sequences.append(X_seq)\n",
    "    return torch.stack(sequences)\n",
    "\n",
    "sequence_length = 15\n",
    "X_test_sequences = create_sequences_test(X_test_tensor, sequence_length)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test_sequences)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0d14865-be88-46ac-984b-64443c7ae052",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_numeric = merged_data_2024_test_cleaned.select_dtypes(include=[float, int])\n",
    "\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_numeric.values, dtype=torch.float32)\n",
    "\n",
    "def create_sequences_test(X, seq_length):\n",
    "    sequences = []\n",
    "    for i in range(seq_length, len(X)):\n",
    "        X_seq = X[i-seq_length:i]\n",
    "        sequences.append(X_seq)\n",
    "    return torch.stack(sequences)\n",
    "\n",
    "sequence_length = 3\n",
    "X_test_sequences = create_sequences_test(X_test_tensor, sequence_length)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test_sequences)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7520f4a7-575a-4791-b01d-bede5e5f3830",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('bagged_model_1.pth', weights_only=True))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch[0].to(device)  \n",
    "        outputs = model(X_batch)         \n",
    "        _, predicted = torch.max(outputs, 1)  \n",
    "        test_predictions.extend(predicted.cpu().numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed29f93c-7aa9-49c9-8705-f8e44e17cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch[0].to(device)  \n",
    "        outputs = model(X_batch)         \n",
    "        _, predicted = torch.max(outputs, 1)  \n",
    "        test_predictions.extend(predicted.cpu().numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "278f2bbb-53cf-4130-879b-41d2cc0d20e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID Predicted_AQI\n",
      "0   1          Good\n",
      "1   2          Good\n",
      "2   3          Good\n",
      "3   4          Good\n",
      "4   5          Good\n"
     ]
    }
   ],
   "source": [
    "label_mapping_legend = {'Good': 0, 'Moderate': 1, 'Poor': 2, 'Severe': 3, 'Unhealthy': 4}\n",
    "\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping_legend.items()}\n",
    "\n",
    "test_predictions_labels = pd.Series([reverse_label_mapping[pred] for pred in test_predictions], name='Predicted_AQI')\n",
    "\n",
    "ID_column = pd.Series(range(1, len(test_predictions) + 1), name='ID')\n",
    "\n",
    "predictions_df = pd.concat([ID_column, test_predictions_labels], axis=1)\n",
    "\n",
    "predictions_df.to_csv('test_predictions_with_labels_sampling.csv', index=False)\n",
    "\n",
    "print(predictions_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57d10868-1958-458e-a3d2-3dc8c40fe32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Good'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b815a0f-9da9-4594-b5c3-22b4dd19de7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
